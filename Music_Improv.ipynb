{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43502353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "088c9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "for file in glob.glob(\"bass_mids/*.MID\"):\n",
    "    # load file into Music21 stream to get list of all the notes and chords\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    # bass parts are the 2nd in these files \n",
    "    notes_to_parse = parts.parts[2].recurse()\n",
    "    for elem in notes_to_parse:\n",
    "        if isinstance(elem, note.Note):\n",
    "            notes.append(str(elem.pitch))\n",
    "        elif isinstance(elem, chord.Chord):\n",
    "            # append chords by encoding the id of every note in the chord together in a string separated by a dot\n",
    "            notes.append('.'.join(str(n) for n in elem.normalOrder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "780f81c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.4', '0.5', '7.0', 'A3', 'A4', 'B-3', 'B-4', 'B-5', 'B3', 'C#4', 'C4', 'C5', 'C6', 'D4', 'D5', 'D6', 'E-4', 'E-5', 'E5', 'F#4', 'F4', 'F5', 'G#4', 'G3', 'G4', 'G5']\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 50\n",
    "# get pitch names\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "print(pitchnames)\n",
    "n_vocab = len(pitchnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7258c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "input= []\n",
    "output = []\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(notes) - sequence_length, 1):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    input.append([note_to_int[char] for char in sequence_in])\n",
    "    output.append(note_to_int[sequence_out])\n",
    "num_patterns = len(input)\n",
    "input = np.reshape(input, (num_patterns, sequence_length, 1))\n",
    "# normalize\n",
    "input = input / float(n_vocab)\n",
    "output = to_categorical(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ffbf004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3567, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2417ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(input.shape[1], input.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5e73152",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weight_checkpoints/music/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0,save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59df9f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(input, output, epochs=2, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ace7db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x177a97af0>\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f82b1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(input.shape[1], input.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.load_weights(\"weight_checkpoints/music/weights-improvement-56-0.1349-bigger.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da1c652e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[5].shape\n",
    "# m, amount we input to give an output, 1\n",
    "# m, t<x> (each step of the classifier, n_values, or one_hots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af46f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x16d938f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x16d938f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(input) -1)\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "pattern = input[start]\n",
    "pred_output = []\n",
    "for note_index in range(500):\n",
    "    # make it 1,50,1 instead of 50,1\n",
    "    pred_input = np.reshape(pattern, (1,len(pattern), 1))\n",
    "    # normalize input\n",
    "    pred_input = pred_input / float(n_vocab)\n",
    "    # predict w/ model\n",
    "    pred = model.predict(pred_input, verbose=0)\n",
    "    # get the most likely index of the next note\n",
    "    index = np.argmax(pred)\n",
    "    # convert to note form \n",
    "    result = int_to_note[index]\n",
    "    # append the result to the output\n",
    "    pred_output.append(result)\n",
    "    pattern = np.append(pattern,index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de8dcd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D5', 'D4', 'D4', 'A4', 'A4', 'A3', 'B-4', 'B-4', 'C#4', 'A3', 'A3', 'A3', 'C5', 'A3', 'D5', 'D4', 'D4', 'C#4', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'G4', 'G4', 'A4', 'A4', 'A3', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'G4', 'G4', 'A4', 'A4', 'A4', 'B-4', 'B-4', 'B-4', 'B-4', 'C5', 'C5', 'C5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4']\n"
     ]
    }
   ],
   "source": [
    "print(pred_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e26ce5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate chords/notes\n",
    "offset = 0\n",
    "output_notes = []\n",
    "for pattern in pred_output:\n",
    "    # for chords\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        chord_notes = pattern.split('.')\n",
    "        notes = []\n",
    "        for cur_note in chord_notes:\n",
    "            n_note = note.Note(int(current_note))\n",
    "            n_note.storeInstrument = instrument.Bass()\n",
    "            notes.append(n_note)\n",
    "        n_chord = chord.Chord(notes)\n",
    "        n_chord.offset = offset\n",
    "        output_notes.append(n_chord)\n",
    "    # for notes (mostly all w/ the bass)\n",
    "    else:\n",
    "        n_note = note.Note(pattern)\n",
    "        n_note.offset = offset\n",
    "        n_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(n_note)\n",
    "    # increase offset \n",
    "    offset+=0.5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e69cf9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/test_out2.mid'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='output/test_out2.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b808b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ac883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a3bbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86a28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5aafca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae9258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec590e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab8acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
