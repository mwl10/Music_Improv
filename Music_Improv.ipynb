{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43502353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088c9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input:  list of file names\n",
    "\n",
    "# output: a list of strings where chords are a grouping of numerical notes, \n",
    "#         separated by '.'; notes are the note names themselves\n",
    "def file_to_note_str(files):\n",
    "    notes = []\n",
    "    for file in files:\n",
    "        # load file into Music21 stream to get list of all the notes and chords\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = None\n",
    "        parts = instrument.partitionByInstrument(midi)\n",
    "        # melodies must be in the same position! (Here the bass lines are in index 2 of the midi)\n",
    "        notes_to_parse = parts.parts[2].recurse()\n",
    "        for elem in notes_to_parse:\n",
    "            if isinstance(elem, note.Note):\n",
    "                notes.append(str(elem.pitch))\n",
    "            elif isinstance(elem, chord.Chord):\n",
    "                # append chords by encoding the id of every note in the chord together in a string separated by a dot\n",
    "                notes.append('.'.join(str(n) for n in elem.normalOrder))\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7258c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the input sequences and corresponding output for the rnn\n",
    "\n",
    "def prep_sequences(notes, sequence_length = 20):\n",
    "    # pitchnames holds all the different notes/chords in a set\n",
    "    pitchnames = sorted(set(notes))\n",
    "    n_vocab = len(pitchnames)\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    input= []\n",
    "    output = []\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "    num_patterns = len(input)\n",
    "    input = np.reshape(input, (num_patterns, sequence_length, 1))\n",
    "    # normalize\n",
    "    input = input / float(n_vocab)\n",
    "    \n",
    "    output = to_categorical(output)\n",
    "    print('pitchnames:\\n', pitchnames)\n",
    "    print('number of notes/chords\\n', n_vocab)\n",
    "    return input, output, n_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2417ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model \n",
    "def create_model(input, n_vocab):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(256, input_shape=(input.shape[1], input.shape[2]), return_sequences=True))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(LSTM(512, return_sequences=True))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(LSTM(256))\n",
    "#     model.add(Dense(256))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(n_vocab))\n",
    "#     model.add(Activation('softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(input.shape[1], input.shape[2]), recurrent_dropout=0.3, return_sequences=True))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea449cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(512, input_shape=(input.shape[1], input.shape[2]), recurrent_dropout=0.3, return_sequences=True))\n",
    "# model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "# model.add(LSTM(512))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(n_vocab))\n",
    "# model.add(Activation('softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e73152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model based on the data, and output checkpoints that you can monitor and input to make predictions \n",
    "def train(model, input, output, epochs=100, batch_size=64):\n",
    "    #print(input)\n",
    "    fp = \"weight_checkpoints/music/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(fp, monitor='loss', verbose=0,save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    print(checkpoint)\n",
    "    model.fit(input, output, epochs=100, batch_size=64, callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31714daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"bass_mids/*.MID\")\n",
    "def train_rnn(files):\n",
    "    notes = file_to_note_str(files)\n",
    "    input, output, n_vocab = prep_sequences(notes)\n",
    "    model = create_model(input, n_vocab)\n",
    "    print(input.shape)\n",
    "    train(model, input, output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cb967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitchnames:\n",
      " ['0.4', '0.5', '1.6', '10.11', '2.6', '3.6', '4.10', '4.6', '6.11', '7.0', 'A3', 'A4', 'B-2', 'B-3', 'B-4', 'B-5', 'B2', 'B3', 'C#4', 'C4', 'C5', 'C6', 'D3', 'D4', 'D5', 'D6', 'E-4', 'E-5', 'E5', 'F#2', 'F#4', 'F4', 'F5', 'G#4', 'G3', 'G4', 'G5']\n",
      "number of notes/chords\n",
      " 37\n",
      "(4855, 20, 1)\n",
      "<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x16a600460>\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x16a653670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x16a653670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 00:37:27.703594: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-09-15 00:37:27.703858: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/76 [======>.......................] - ETA: 34s - loss: 3.9216"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lm/977wpgds1gs1n_kthn20n8sw0000gn/T/ipykernel_6718/2401843809.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/lm/977wpgds1gs1n_kthn20n8sw0000gn/T/ipykernel_6718/201072418.py\u001b[0m in \u001b[0;36mtrain_rnn\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lm/977wpgds1gs1n_kthn20n8sw0000gn/T/ipykernel_6718/2215958059.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, input, output, epochs, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mvenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mvenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mvenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mvenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mvenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mvenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mvenv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_rnn(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb29b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitchnames:\n",
      " ['0.4', '0.5', '1.6', '10.11', '2.6', '3.6', '4.10', '4.6', '6.11', '7.0', 'A3', 'A4', 'B-2', 'B-3', 'B-4', 'B-5', 'B2', 'B3', 'C#4', 'C4', 'C5', 'C6', 'D3', 'D4', 'D5', 'D6', 'E-4', 'E-5', 'E5', 'F#2', 'F#4', 'F4', 'F5', 'G#4', 'G3', 'G4', 'G5']\n",
      "number of notes/chords\n",
      " 37\n"
     ]
    }
   ],
   "source": [
    "notes = file_to_note_str(files)\n",
    "input, output, n_vocab = prep_sequences(notes)\n",
    "pitchnames = sorted(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f82b1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(256, input_shape=(input.shape[1], input.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(LSTM(512, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dense(256))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(n_vocab))\n",
    "# model.add(Activation('softmax'))\n",
    "# model.load_weights(\"weight_checkpoints/music/weights-improvement-109-0.0711.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a840a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated model \n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(input.shape[1], input.shape[2]), recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "model.add(LSTM(512))\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.load_weights(\"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af46f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x17a6c19d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x17a6c19d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(input) -1)\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "pattern = input[start]\n",
    "pred_output = []\n",
    "for note_index in range(500):\n",
    "    # make it 1,50,1 instead of 50,1\n",
    "    pred_input = np.reshape(pattern, (1,len(pattern), 1))\n",
    "    # normalize input\n",
    "    pred_input = pred_input / float(n_vocab)\n",
    "    # predict w/ model\n",
    "    pred = model.predict(pred_input, verbose=0)\n",
    "    # get the most likely index of the next note => can change this to any somewhat likely index for more spontaneity\n",
    "    index = np.argmax(pred)\n",
    "    # convert to note form \n",
    "    result = int_to_note[index]\n",
    "    # append the result to the output\n",
    "    pred_output.append(result)\n",
    "    pattern = np.append(pattern,index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de8dcd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A4', 'A4', 'A4', 'A4', 'A4', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'B-2', '4.10', 'B-2', '4.10', 'B-2', '2.6', 'D3', '2.6', 'D3', '6.11', 'B2', '6.11', 'B2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2', '4.6', 'F#2']\n"
     ]
    }
   ],
   "source": [
    "print(pred_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e26ce5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate chords/notes\n",
    "offset = 0\n",
    "output_notes = []\n",
    "for pattern in pred_output:\n",
    "    # for chords\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        chord_notes = pattern.split('.')\n",
    "        notes = []\n",
    "        for cur_note in chord_notes:\n",
    "            n_note = note.Note(int(cur_note))\n",
    "            n_note.storeInstrument = instrument.Bass()\n",
    "            notes.append(n_note)\n",
    "        n_chord = chord.Chord(notes)\n",
    "        n_chord.offset = offset\n",
    "        output_notes.append(n_chord)\n",
    "    # for notes (mostly all w/ the bass)\n",
    "    else:\n",
    "        n_note = note.Note(pattern)\n",
    "        n_note.offset = offset\n",
    "        n_note.storedInstrument = instrument.Bass()\n",
    "        output_notes.append(n_note)\n",
    "    # increase offset \n",
    "    offset+=0.5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e69cf9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/test_out4.mid'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='output/test_out4.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b808b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid2wav('output/my_music.midi')\n",
    "# IPython.display.Audio('./output/rendered.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ac883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a3bbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86a28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5aafca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae9258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec590e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab8acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
